{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR customeracquisitionapp PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AUTOML FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def gradientboostingclassifier(df, labels, features):\n",
    "    sparkDF.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = (sparkDF.toPandas())\n",
    "    model_gbm_sklearn = GradientBoostingClassifier(**optuna_parameters)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[features], df[labels])\n",
    "    model_gbm_sklearn.fit(X_train, y_train)\n",
    "    display(\" Accuracy of Model : %s\" %\n",
    "            model_gbm_sklearn.score(X_test, y_test))\n",
    "\n",
    "    data = {'model': model_gbm_sklearn,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'label': labels,\n",
    "            'columnNames': df.columns}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('spark://0.0.0.0:0000').getOrCreate()\n",
    "#%run customeracquisitionappHooks.ipynb\n",
    "try:\n",
    "\t\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRAIN MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run customeracquisitionappHooks.ipynb\n",
    "try:\n",
    "\t#mlPreExecutionHook()\n",
    "\n",
    "\tdataAutoML=gradientboostingclassifier(classificationmanual, [\"Count\", \"Customer ID\", \"Store Number\", \"Zip\", \"DriveTime\", \"Length of Residense\", \"MOR BANK: UPSCALE MERCHANDISE BUYER\", \"Customer_Lon\", \"Customer_Lat\", \"Store ID\", \"Store_Lon\", \"Store_Lat\", \"City_stringindexer\", \"Product_Category_stringindexer\", \"Product_Sub-Category_stringindexer\", \"Customer Segment_stringindexer\", \"First Name_stringindexer\", \"Last Name_stringindexer\", \"Address_stringindexer\", \"State_stringindexer\", \"MOSAIC HOUSEHOLD_stringindexer\", \"MOSAIC DESCRIPTION_stringindexer\"], \"Channel_stringindexer\")\n",
    "\n",
    "\t#mlPostExecutionHook(dataAutoML)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
